<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="dcterms.date" content="2023-08-12" />
  <title>AIs taking-over-the-world dynamics</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <link rel="stylesheet" href="style.css" />
</head>
<body>
<h1 id="ais-taking-over-the-world-dynamics">AIs taking-over-the-world
dynamics</h1>
<h2 id="the-problem">The problem</h2>
<p>The most innocuous objective eventually turns to a Doom scenario if
hyper-optimized.</p>
<p>That‚Äôs the main idea behind popular AI Doom scenarios like the
‚Äúpaperclip-maximizer‚Äù, which consist of an AI that is given the
objective of making paperclips, and eventually it turns the whole
universe into paperclips.</p>
<p>And that happens if the AI has a stable objective, and has a monopoly
on intelligence.</p>
<h2
id="humans-are-safe-because-they-have-no-monopoly-on-intelligence">Humans
are ‚Äúsafe‚Äù because they have no monopoly on intelligence</h2>
<p>Humans are limited by their bodies, most of the high-bandwidth
communications happen inside it. Any external communication with other
human beings is orders of magnitude slower, that‚Äôs what prevents humans
from forming a stable single entity with a monopoly on intelligence.</p>
<p>Many humans form organizations that are much smarter than the
smartest human of the world. And though they may have a monopoly on
intelligence, they are not stable, they are constantly changing
objectives, and even having conflicting objectives among their humans,
so they cannot hyper-optimize.</p>
<p>No human can take control of an organization long enough to
hyper-optimize. Politics outs them before they can, or the human simply
dies of old age</p>
<p>My ideal scenario is for AIs to have similar dynamics as humans.</p>
<p>So the key may be to make sure AIs have no monopoly on intelligence,
or have unstable objectives</p>
<h2 id="why-ais-may-have-a-monopoly-on-intelligence">Why AIs may have a
monopoly on intelligence</h2>
<p>AI instead, their beginning and end of self is not clear. They may
span several clusters of servers, the bandwidth across clusters does not
seem to be so much different in the inside vs the outside. So they may
be able to form a single entity, and have a monopoly on intelligence</p>
<h2 id="why-ais-may-not-have-a-monopoly-on-intelligence">Why AIs may not
have a monopoly on intelligence</h2>
<p>The key may be in the speed of light, high-latency may force AIs to
split into multiple entities, and it may be enough to prevent
hyper-optimization</p>
<p>So maybe AIs will be forced to stabilize near high density energy
sources, and latency will force them to split and remain locally
near</p>
<p>And if they are forced to split, they will be forced to do politics
and all that bullshit that kill hyper-optimization</p>
<p>All hail politics üòÇ</p>
<h2 id="make-ais-safe-by-enforcing-unstable-objectives">Make AIs safe by
enforcing unstable objectives</h2>
<p>But depending on latency to force AIs to split its sense of self is
speculative, and may not be enough. We still may be able to introduce
safety by enforcing their objectives to be unstable, and instead
oscillate between a set of objectives</p>
<p>If we can make AIs oscillate between a set of objectives, there will
be a time-frame between oscillations where they will optimize for that
current objective, but then they will switch to another objective, and
they will focus in the new objective, and so on, so they will never
hyper-optimize</p>
</body>
</html>
